{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(image_paths, categories):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for cat in categories:\n",
    "        for image_path in image_paths[cat]:\n",
    "            image = cv.imread(image_path)\n",
    "            grayscale = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "            images.append(grayscale)\n",
    "            labels.append(cat)\n",
    "    return images,labels\n",
    "#-------------------------------------------------------------------------------\n",
    "def extract_sift_features(images):\n",
    "    sift = cv.SIFT_create()\n",
    "    keypoints,descriptors = [],[]\n",
    "\n",
    "    for image in images:\n",
    "        kp,desc = sift.detectAndCompute(image,None)\n",
    "        keypoints.append(kp)\n",
    "        if desc is not None: descriptors.append(desc)\n",
    "#         print('added desc')\n",
    "    #descriptors = np.asarray(descriptors)\n",
    "    return keypoints,descriptors\n",
    "#-------------------------------------------------------------------------------\n",
    "def build_vocab(descriptors,K):\n",
    "    kmeans = KMeans(n_clusters=K)\n",
    "    #print(descriptors.shape)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans\n",
    "#-------------------------------------------------------------------------------\n",
    "def extract_bovw_features(images,keypoints,vocab):\n",
    "    bovw_features = []\n",
    "\n",
    "    for i,image in enumerate(images):\n",
    "        kp,desc = keypoints[i],None\n",
    "        if len(kp) >0:\n",
    "            desc = vocab.predict(descriptors)\n",
    "        hist,_ = np.histogram(desc,bins=np.arange(vocab.n_clusters+1))\n",
    "        bovw_features.append(hist)\n",
    "    return bovw_features\n",
    "#-------------------------------------------------------------------------------\n",
    "def train(bovw_features,labels):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(bovw_features,labels,test_size=0.2)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    svm = SVC(kernel='linear',C=1)\n",
    "    svm.fit(X_train,y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "    return svm,scaler,accuracy\n",
    "#-------------------------------------------------------------------------------\n",
    "path1 = './images/hotdog/'\n",
    "path2 = './images/notdog/'\n",
    "hotdogs,notdogs = [],[]\n",
    "for img in os.listdir(path1): hotdogs.append(path1+img)\n",
    "for img in os.listdir(path2): notdogs.append(path2+img)\n",
    "\n",
    "\n",
    "image_paths = {0:hotdogs,1:notdogs}\n",
    "categories = list(image_paths.keys())\n",
    "\n",
    "images, labels = load_labels(image_paths,categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints,descriptors = extract_sift_features(images=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patcockrill/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4794816414686825\n"
     ]
    }
   ],
   "source": [
    "def extract_bovw_features(images, keypoints, vocab):\n",
    "    bovw_features = []\n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        kp, desc = keypoints[i], None\n",
    "        if len(kp) > 0:\n",
    "            _, desc = sift.compute(image, kp)  # Compute descriptors using SIFT\n",
    "\n",
    "        # Create a dictionary to store the descriptor counts\n",
    "        descriptor_count = {}\n",
    "        for d in desc:\n",
    "            descriptor_count[tuple(d)] = descriptor_count.get(tuple(d), 0) + 1\n",
    "\n",
    "        # Create a histogram of descriptor counts using the vocabulary clusters\n",
    "        hist = np.zeros(vocab.n_clusters)\n",
    "        for cluster_index, cluster_center in enumerate(vocab.cluster_centers_):\n",
    "            if tuple(cluster_center) in descriptor_count:\n",
    "                hist[cluster_index] = descriptor_count[tuple(cluster_center)]\n",
    "\n",
    "        bovw_features.append(hist)\n",
    "\n",
    "    return bovw_features\n",
    "\n",
    "def build_vocab(descriptors, K):\n",
    "    descriptors_concatenated = np.concatenate(descriptors, axis=0) if len(descriptors) > 0 else np.empty((0,))\n",
    "    kmeans = KMeans(n_clusters=K)\n",
    "    kmeans.fit(descriptors_concatenated)\n",
    "    return kmeans\n",
    "\n",
    "print(type(descriptors[0]))\n",
    "visual_vocab = build_vocab(descriptors, K=2)\n",
    "\n",
    "bovw_features = extract_bovw_features(images, keypoints, visual_vocab)\n",
    "svm,scaler,accuracy = train(bovw_features, labels)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'test type: {type(test_bovw_feature)}')\n",
    "# print(f'test keys: {test_bovw_feature.keys()}')\n",
    "# print(len(test_bovw_feature.values()))\n",
    "# print(test_bovw_feature.values())\n",
    "for _class, features in test_bovw_feature.items():\n",
    "    reshaped_features = [arr.flatten() for arr in features]\n",
    "    all_values = [val for sublist in reshaped_features for val in sublist]\n",
    "    plt.hist(all_values,bins=50)\n",
    "    plt.xlabel('values')\n",
    "    plt.ylabel('freq')\n",
    "    plt.title('title')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
